\form#0:\[ sgn(x) = \begin{cases} 1 & \text{if } x>0\\ 0 & \text{if } x=0\\ -1& \text{if } x<0 \end{cases} \]
\form#1:\[ sgn(x) \equiv \begin{cases} 1 & \text{if } x > 0 \\ 0 & \text{if } x = 0 \\ -1& \text{if } x < 0 \end{cases} \]
\form#2:\[ x^{+} \equiv \begin{cases} x & \text{if } x \geq 0\\ 0 & \text{if } x < 0\\ \end{cases} \]
\form#3:\[ \tau( x, y ) \equiv sgn(x) \left( \lvert x \rvert - y \right)^{+} \]
\form#4:$ \forall i, j A_{i,j} = f( i, j ) $
\form#5:\begin{algorithm} \caption{ISTA with backtracking line search and duality gap convergence criteria} \begin{algorithmic}[1] \Statex \Input\tikzmark{k} \Statex $X \in \mathbb{R}^{n \times p} $ \Comment{ The design matrix } \Statex $Y \in \mathbb{R}^n$ \Comment{ The vector of predictors } \Statex $\beta \in \mathbb{R}^n$ \Comment{ Starting vector } \Statex $L_0 \in \mathbb{R}$ \Comment{ Initial Lipschitz constant, used by backtracking line search } \Statex $\lambda \in \mathbb{R}$ \Comment{ Grid element } \Statex $\eta \in \mathbb{R}$ \Comment{ Step size when updating Lipschitz constant } \Statex $\mathcal{D} \in \mathbb{R}$ \Comment{ Duality gap target }\tikzmark{l} \State $\widetilde{\beta} \gets \beta$ \Comment{ Make a copy of $\beta$ that will be updated during back tracking.} \Do \State $ \widetilde{\beta} \gets \tau( \beta - \frac{1}{L} \nabla f( X, Y, \widetilde{\beta}, L ) )$ \While{ $f_{\beta} ( X, Y, \widetilde{\beta} ) > f_{\widetilde{\beta}}( X, Y, \widetilde{\beta}, \beta_, L) $ } \State $L \gets \eta L$ \State $ \widetilde{\beta} \gets \tau( \beta - \frac{1}{L} \nabla f( X, Y, \beta ) )$ \EndWhile \State $\beta \gets \tau( \beta - \frac{1}{L} \nabla f( X, Y, \beta, L ) )$ \Comment{ Update $\beta$ once $L$ is sufficiently large.} \doWhile{ DG $( X, Y, \beta, \lambda ) > \mathcal{D}$ }\\ \end{algorithmic} \Return $\beta$ \end{algorithm}
\form#6:\begin{algorithm} \caption{ISTA with backtracking line search and duality gap convergence criteria} \begin{algorithmic}[1] \Statex \Input\tikzmark{k} \Statex $X \in \mathbb{R}^{n \times p} $ \Comment{ The design matrix } \Statex $Y \in \mathbb{R}^n$ \Comment{ The vector of predictors } \Statex $\beta \in \mathbb{R}^n$ \Comment{ Starting vector } \Statex $L_0 \in \mathbb{R}$ \Comment{ Initial Lipschitz constant, used by backtracking line search } \Statex $\lambda \in \mathbb{R}$ \Comment{ Grid element } \Statex $\eta \in \mathbb{R}$ \Comment{ Step size when updating Lipschitz constant } \Statex $\mathcal{D} \in \mathbb{R}$ \Comment{ Duality gap target }\tikzmark{l} \State $\widetilde{\beta} \gets \beta$ \Comment{ Make a copy of $\beta$ that will be updated during back tracking.} \For $i \in \{ 1, 2, \dots, n \}$ \State $ \widetilde{\beta} \gets \tau( \beta - \frac{1}{L} \nabla f( X, Y, \widetilde{\beta}, L ) )$ \While{ $f_{\beta} ( X, Y, \widetilde{\beta} ) > f_{\widetilde{\beta}}( X, Y, \widetilde{\beta}, \beta_, L) $ } \State $L \gets \eta L$ \State $ \widetilde{\beta} \gets \tau( \beta - \frac{1}{L} \nabla f( X, Y, \beta ) )$ \EndWhile \State $\beta \gets \tau( \beta - \frac{1}{L} \nabla f( X, Y, \beta, L ) )$ \Comment{ Update $\beta$ once $L$ is sufficiently large.} \EndFor \end{algorithmic} \Return $\beta$ \end{algorithm}
\form#7:\begin{algorithm} \caption{ISTA with backtracking line search and duality gap convergence criteria} \begin{algorithmic}[1] \Statex \Input\tikzmark{k} \Statex $X \in \mathbb{R}^{n \times p} $ \Comment{ The design matrix } \Statex $Y \in \mathbb{R}^n$ \Comment{ The vector of predictors } \Statex $\beta \in \mathbb{R}^n$ \Comment{ Starting vector } \Statex $L_0 \in \mathbb{R}$ \Comment{ Initial Lipschitz constant, used by backtracking line search } \Statex $\lambda \in \mathbb{R}$ \Comment{ Grid element } \Statex $\eta \in \mathbb{R}$ \Comment{ Step size when updating Lipschitz constant } \Statex $\mathcal{D} \in \mathbb{R}$ \Comment{ Duality gap target }\tikzmark{l} \State $\widetilde{\beta} \gets \beta$ \Comment{ Make a copy of $\beta$ that will be updated during back tracking.} \For{$i \in \{ 1, 2, \dots, n \}$} \State $ \widetilde{\beta} \gets \tau( \beta - \frac{1}{L} \nabla f( X, Y, \widetilde{\beta}, L ) )$ \While{ $f_{\beta} ( X, Y, \widetilde{\beta} ) > f_{\widetilde{\beta}}( X, Y, \widetilde{\beta}, \beta_, L) $ } \State $L \gets \eta L$ \State $ \widetilde{\beta} \gets \tau( \beta - \frac{1}{L} \nabla f( X, Y, \beta ) )$ \EndWhile \State $\beta \gets \tau( \beta - \frac{1}{L} \nabla f( X, Y, \beta, L ) )$ \Comment{ Update $\beta$ once $L$ is sufficiently large.} \EndFor \end{algorithmic} \Return $\beta$ \end{algorithm}
\form#8:\begin{algorithm} \caption{ISTA with backtracking line search and iterative convergence criteria} \begin{algorithmic}[1] \Statex \Input\tikzmark{k} \Statex $X \in \mathbb{R}^{n \times p} $ \Comment{ The design matrix } \Statex $Y \in \mathbb{R}^n$ \Comment{ The vector of predictors } \Statex $\beta \in \mathbb{R}^n$ \Comment{ Starting vector } \Statex $L_0 \in \mathbb{R}$ \Comment{ Initial Lipschitz constant, used by backtracking line search } \Statex $\lambda \in \mathbb{R}$ \Comment{ Grid element } \Statex $\eta \in \mathbb{R}$ \Comment{ Step size when updating Lipschitz constant } \Statex $\mathcal{N} \in \mathbb{N}$ \Comment{ Number of times to run the algorithm }\tikzmark{l} \State $\widetilde{\beta} \gets \beta$ \Comment{ Make a copy of $\beta$ that will be updated during back tracking.} \For{$i \in \{ 1, 2, \dots, N \}$} \State $ \widetilde{\beta} \gets \tau( \beta - \frac{1}{L} \nabla f( X, Y, \widetilde{\beta}, L ) )$ \While{ $f_{\beta} ( X, Y, \widetilde{\beta} ) > f_{\widetilde{\beta}}( X, Y, \widetilde{\beta}, \beta_, L) $ } \State $L \gets \eta L$ \State $ \widetilde{\beta} \gets \tau( \beta - \frac{1}{L} \nabla f( X, Y, \beta ) )$ \EndWhile \State $\beta \gets \tau( \beta - \frac{1}{L} \nabla f( X, Y, \beta, L ) )$ \Comment{ Update $\beta$ once $L$ is sufficiently large.} \EndFor \end{algorithmic} \Return $\beta$ \end{algorithm}
\form#9:\begin{algorithm} \caption{Coordinate Descent with duality gap convergence criteria} \begin{algorithmic}[1] \Statex \Input\tikzmark{k} \Statex $X \in \mathbb{R}^{n \times p} $ \Comment{ The design matrix } \Statex $Y \in \mathbb{R}^n$ \Comment{ The vector of predictors } \Statex $\beta \in \mathbb{R}^n$ \Comment{ Starting vector } \Statex $\lambda \in \mathbb{R}$ \Comment{ Grid element } \Statex $\mathcal{D} \in \mathbb{R}$ \Comment{ Duality gap target }\tikzmark{l} \State $\widetilde{\beta} \gets \beta$ \Comment{ Make a copy of $\beta$ } \Do \For{ $i \in 1, 2, \dots, p$ } \State $t \gets \frac{ \lambda }{ \LTwoSqr{ X_i } }$ \Comment{ Scale grid element by norm of the i'th column of design matrix } \State $X_{-i} \gets X_{ \forall j \neq i}$ \Comment{ Take all columns of design matrix not equal to $i$ } \State $\widetilde{\beta}_{-i} \gets \widetilde{\beta}_{ \forall j \neq i}$ \Comment{ Take all elements of predictors vectors not equal to $i$ } \State $r \gets \frac{ X_i^T\left( Y - X_{-i} \beta_{-i}\right) }{ \LTwoSqr{ X_i } }$ \Comment{ Compute the scaled residual } \State $\widetilde{\beta}_i \gets \frac{1}{2}\tau \left( 2 \times r, t \right)$ \Comment{ Update the i'th element of Beta } \EndFor \doWhile{ DG $( X, Y, \widetilde{\beta}, \lambda ) > \mathcal{D}$ }\\ \end{algorithmic} \Return $\widetilde{\beta}$ \end{algorithm}
\form#10:\begin{algorithm} \caption{ISTA with backtracking line search and iterative convergence criteria} \begin{algorithmic}[1] \Statex \Input\tikzmark{k} \Statex $X \in \mathbb{R}^{n \times p} $ \Comment{ The design matrix } \Statex $Y \in \mathbb{R}^n$ \Comment{ The vector of predictors } \Statex $\beta \in \mathbb{R}^n$ \Comment{ Starting vector } \Statex $L_0 \in \mathbb{R}$ \Comment{ Initial Lipschitz constant, used by backtracking line search } \Statex $\lambda \in \mathbb{R}$ \Comment{ Grid element } \Statex $\eta \in \mathbb{R}$ \Comment{ Step size when updating Lipschitz constant } \Statex $\mathcal{N} \in \mathbb{N}$ \Comment{ Number of times to run the algorithm }\tikzmark{l} \State $\widetilde{\beta} \gets \beta$ \Comment{ Make a copy of $\beta$ that will be updated during back tracking.} \For{$i \in \{ 1, 2, \dots, \mathcal{N} \}$} \State $ \widetilde{\beta} \gets \tau( \beta - \frac{1}{L} \nabla f( X, Y, \widetilde{\beta}, L ) )$ \While{ $f_{\beta} ( X, Y, \widetilde{\beta} ) > f_{\widetilde{\beta}}( X, Y, \widetilde{\beta}, \beta_, L) $ } \State $L \gets \eta L$ \State $ \widetilde{\beta} \gets \tau( \beta - \frac{1}{L} \nabla f( X, Y, \beta ) )$ \EndWhile \State $\beta \gets \tau( \beta - \frac{1}{L} \nabla f( X, Y, \beta, L ) )$ \Comment{ Update $\beta$ once $L$ is sufficiently large.} \EndFor \end{algorithmic} \Return $\beta$ \end{algorithm}
